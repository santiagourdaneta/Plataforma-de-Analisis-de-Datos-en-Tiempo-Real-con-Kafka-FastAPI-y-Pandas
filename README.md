# ‚ö° Plataforma de An√°lisis de Datos en Tiempo Real: Kafka, FastAPI y Pandas

Esta es una soluci√≥n de arquitectura de datos en tiempo real (Real-Time Data Platform) dise√±ada para la ingesta, procesamiento, an√°lisis y visualizaci√≥n de flujos de datos continuos. El proyecto demuestra un *pipeline* escalable y de alta disponibilidad, ideal para monitoreo de sistemas, IoT o an√°lisis financiero.

## ‚öôÔ∏è Arquitectura de la Soluci√≥n

El sistema se basa en una arquitectura de microservicios y streaming, donde cada componente cumple una funci√≥n espec√≠fica:

| Componente | Tecnolog√≠a | Rol en el Pipeline |
| :--- | :--- | :--- |
| **Ingesta/Mensajer√≠a** | **Apache Kafka** | Broker de mensajer√≠a de alta throughput para desacoplar el productor del consumidor y asegurar la persistencia del flujo de datos. |
| **Procesamiento** | **Python (Consumer) + Pandas** | Consume datos de Kafka y realiza transformaciones, agregaciones y an√°lisis estad√≠sticos r√°pidos en memoria. |
| **API de Datos** | **FastAPI (Integrado)** | Sirve los resultados del an√°lisis en tiempo real a trav√©s de endpoints RESTful as√≠ncronos de baja latencia (Uvicorn). |
| **Visualizaci√≥n** | **Plotly / Dash** | Dashboard interactivo que se actualiza en tiempo real para reflejar las m√©tricas de negocio. |
| **Orquestaci√≥n** | **Docker & Docker Compose** | Contenedorizaci√≥n de Zookeeper y Kafka para un despliegue r√°pido y consistente en cualquier entorno. |

## ‚ú® Caracter√≠sticas Clave

* **Baja Latencia y Alta Disponibilidad:** Utilizaci√≥n de Kafka para gestionar picos de tr√°fico y garantizar la entrega de datos.
* **An√°lisis Eficiente:** Pandas se utiliza para realizar c√°lculos complejos y anal√≠tica descriptiva (promedios, m√°ximos, agregaciones) sobre el *stream* de datos.
* **Despliegue Simplificado:** Configuraci√≥n completa de servicios con `docker-compose.yml`.
* **Visualizaci√≥n Din√°mica:** Dashboards construidos con Plotly/Dash que permiten la toma de decisiones inmediata.

## üöÄ Configuraci√≥n y Ejecuci√≥n

### Requisitos Previos

* **Python 3.8+**
* **Docker Desktop** (para levantar Kafka y Zookeeper)
* **Git**

### 1. Clonar el Repositorio

```bash
git clone [https://github.com/santiagourdaneta/Plataforma-de-Analisis-de-Datos-en-Tiempo-Real-con-Kafka-FastAPI-y-Pandas.git](https://github.com/santiagourdaneta/Plataforma-de-Analisis-de-Datos-en-Tiempo-Real-con-Kafka-FastAPI-y-Pandas.git)
cd Plataforma-de-Analisis-de-Datos-en-Tiempo-Real-con-Kafka-FastAPI-y-Pandas

2. Iniciar Servicios de Mensajer√≠a (Kafka)
Desde la ra√≠z del proyecto, levanta los servicios de Kafka y Zookeeper usando Docker Compose:

docker compose up -d

3. Instalar Dependencias de Python
Instala las librer√≠as requeridas (FastAPI, Pandas, kafka-python, Dash, Plotly, etc.):

pip install -r requirements.txt

4. Ejecutar el Pipeline
Abre tres terminales separadas:

1 (Productor) producer.py python producer.py Simula y env√≠a datos continuos a un topic de Kafka.
2 (Consumidor/API) consumer_processor.py python consumer_processor.py Consume datos, los procesa con Pandas y sirve la API/Dash.

5. Acceder a la Plataforma
Navega a la URL proporcionada por el script consumer_processor.py (generalmente http://127.0.0.1:8050/) para ver el dashboard de datos en tiempo real.

üõë Detener Servicios
Para detener todos los contenedores de Docker:

docker compose down




